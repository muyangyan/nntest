{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d73dfc7e-9ce8-4b76-b269-8517a5ac4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "    \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9a68a5-8007-401b-a245-7d09a0f05cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3498767b-91d2-4b96-8292-e086d2b73051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_one_hot(x):\n",
    "    b = np.zeros((len(x),10))\n",
    "    for i in range(len(x)):\n",
    "        a = np.zeros(10)\n",
    "        a[x[i]] = 1\n",
    "        b[i] = a\n",
    "    return b\n",
    "data = np.array(data)\n",
    "test_data = data[0:999]\n",
    "train_data = data[1000:len(data)]\n",
    "train_labels_number = train_data[:, 0]\n",
    "train_labels = convert_one_hot(train_labels_number)\n",
    "train_layers = train_data[:, 1:train_data.shape[0]]/255\n",
    "test_labels_number = test_data[:, 0]\n",
    "test_labels = convert_one_hot(test_labels_number)\n",
    "test_layers = test_data[:, 1:test_data.shape[0]]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5f68341-b2e8-4f22-a264-79bc10142374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    return(np.exp(x)/np.square(np.exp(x)+1) + 1e-15)\n",
    "\n",
    "def ReLU(x):\n",
    "    #return 1/(1 + np.exp(-x))\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def d_ReLU(x):\n",
    "    #return(np.exp(x)/np.square(np.exp(x)+1))\n",
    "    return x > 0\n",
    "\n",
    "def norm(x):\n",
    "    #print(np.max(x))\n",
    "    return x/(np.max(x) + 1e-15)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "def ssd(y, p): #sum of squared differences\n",
    "    squared_diff = np.square(y - p)\n",
    "    return np.sum(squared_diff)\n",
    "\n",
    "def d_sd(y, p): #derivative of squared difference\n",
    "    return 2 * (y - p)\n",
    "\n",
    "def sum_cross_ent(y, p):\n",
    "    p += np.full(p.shape, 1e-15) #to prevent log(0)\n",
    "    return np.sum(-(y * np.log(p) + (1 - y) * np.log(1 - p)))\n",
    "\n",
    "def d_cross_ent(y, p):\n",
    "    p += np.full(p.shape, 1e-15) #to prevent division by zero\n",
    "    return ((1 - y) / (1 - p)) - (y / p)\n",
    "\n",
    "class Net: # accepts a tuple indicating the number of nodes in each layer. contains the weights array and biases vector for each layer\n",
    "\n",
    "    def __init__(self, layers): # must have atleast 2 layers (2 items in the layers tuple)\n",
    "        self.layers = layers #tuple\n",
    "        self.weights = []\n",
    "        for i in range(1, len(layers)):\n",
    "            self.weights.append(np.random.rand(layers[i],layers[i-1]))\n",
    "        self.biases = []\n",
    "        for i in range(1, len(layers)):\n",
    "            self.biases.append(np.random.rand(layers[i]))\n",
    "        self.net = [] # contains activations\n",
    "        for i in range(len(layers)):\n",
    "            self.net.append(np.zeros((layers[i])))\n",
    "\n",
    "    def dump(self):\n",
    "        print(\"DUMP========\")\n",
    "        print(self.biases)\n",
    "        print(self.weights)\n",
    "        \n",
    "    def act(self, x):\n",
    "        return sigmoid(x)\n",
    "    \n",
    "    def d_act(self, x):\n",
    "        return d_sigmoid(x)\n",
    "        \n",
    "    def loss(self, expected, actual): #for one training example\n",
    "        #return sum_cross_ent(expected, actual)\n",
    "        return ssd(expected, actual)\n",
    "    \n",
    "    def d_loss(self, expected, actual): #for one training example\n",
    "        #return d_cross_ent(expected, actual)\n",
    "        return d_sd(expected, actual)\n",
    "    \n",
    "    def emp_loss(self, labels, inputs): #empirical loss, for whole testing set\n",
    "        loss_array = np.zeros((len(inputs)))\n",
    "        for i in range(len(inputs)):\n",
    "            output = self.forward(inputs[i])\n",
    "            loss_array[i] = self.loss(labels[i], output)\n",
    "        return np.mean(loss_array)\n",
    "    \n",
    "    def acc(self, labels_num, inputs):\n",
    "        successes = 0\n",
    "        for i in range(len(inputs)):\n",
    "            output = self.forward(inputs[i])\n",
    "            prediction = np.where(output == output.max())[0][0]\n",
    "            if prediction == labels_num[i]:\n",
    "                successes+=1\n",
    "        return successes/len(inputs)\n",
    "    \n",
    "    def forward(self, input_layer):\n",
    "        self.net[0] = input_layer\n",
    "        for i in range(1, len(self.net)):\n",
    "            self.net[i] = self.act(np.dot(self.weights[i-1], self.net[i-1]) + self.biases[i-1])\n",
    "        out = self.net[len(self.net)-1]\n",
    "        normalized = norm(out)\n",
    "        return softmax(normalized)\n",
    "\n",
    "    def backprop(self, label, example): # for one training example\n",
    "        l = self.forward(example)\n",
    "        d_w = []\n",
    "        for i in range(len(self.layers)-1):\n",
    "            d_w.append(np.zeros((self.layers[i+1],self.layers[i])))\n",
    "        d_b = []\n",
    "        for i in range(len(self.layers)-1):\n",
    "            d_b.append(np.zeros((self.layers[i+1])))\n",
    "        d_a = [] \n",
    "        for i in range(len(self.layers)):\n",
    "            d_a.append(np.zeros((self.layers[i])))\n",
    "\n",
    "        #d_cost = 2 * (self.net[len(self.layers)-1] - label)\n",
    "        d_a[len(self.layers)-1] = self.d_loss(self.net[len(self.layers)-1], label)\n",
    "\n",
    "        for i in reversed(range(len(self.layers)-1)):\n",
    "            for j in range(len(self.net[i])):\n",
    "                for k in range(len(self.net[i+1])):\n",
    "                    #calculates z for the whole layer (layer i)\n",
    "                    z_layer = np.dot(self.weights[i][k], self.net[i]) + self.biases[i][k]\n",
    "                    #calculates z for this specific node (layer i, index j)\n",
    "                    z = self.weights[i][k][j] * self.net[i][j] + self.biases[i][k]\n",
    "                    #calculates the suggested change \n",
    "                    d_a[i][j] += (self.weights[i][k][j] * self.d_act(z_layer) * d_a[i+1][k])/len(self.net[i+1])\n",
    "                    d_b[i][k] += (self.d_act(z_layer) * d_a[i+1][k])/len(self.net[i+1])\n",
    "                    d_w[i][k][j] = self.net[i][j] * self.d_act(z) * d_a[i+1][k]\n",
    "        return d_w, d_b\n",
    "\n",
    "    def train(self, data, labels, batch_size, rate, *, batches=0): #labels and data are arrays of vectors (or 2d arrays), 1 epoch\n",
    "        #np.random.shuffle(data)\n",
    "        data_batched = np.zeros((math.floor(len(data)/batch_size), batch_size, self.layers[0]))\n",
    "        labels_batched = np.zeros((math.floor(len(data)/batch_size), batch_size, self.layers[len(self.layers) - 1]))\n",
    "        for i in range(math.floor(len(data)/batch_size)):\n",
    "            for j in range(batch_size):\n",
    "                data_batched[i][j] = data[i*batch_size + j]\n",
    "                labels_batched[i][j] = labels[i*batch_size + j]\n",
    "        \n",
    "        batch_count = batches\n",
    "        if (batches == 0):\n",
    "            batch_count = len(data_batched)\n",
    "        for i in range(batch_count):\n",
    "            #self.dump()\n",
    "            print(\"\\n\\nbatch\", i)\n",
    "            d_weights_list = []\n",
    "            d_biases_list = []\n",
    "            d_weights = []\n",
    "            for j in range(1, len(self.layers)):\n",
    "                d_weights.append(np.zeros((self.layers[j],self.layers[j-1])))\n",
    "            d_biases = []\n",
    "            for j in range(len(self.layers)-1):\n",
    "                d_biases.append(np.zeros((self.layers[j+1])))\n",
    "            for j in range(len(data_batched[i])):\n",
    "                this_d_weights, this_d_biases = self.backprop(labels_batched[i][j], data_batched[i][j])\n",
    "                d_weights_list.append(this_d_weights)\n",
    "                d_biases_list.append(this_d_biases)\n",
    "            for j in range(len(self.layers)-1):    \n",
    "                for k in range(len(data_batched[i])):\n",
    "                    d_weights[j] += d_weights_list[k][j]\n",
    "                    d_biases[j] += d_biases_list[k][j]\n",
    "                d_weights[j] = d_weights[j]/len(data_batched[j])\n",
    "                d_biases[j] = d_biases[j]/len(data_batched[j])\n",
    "                self.weights[j] = np.subtract(self.weights[j], rate * d_weights[j])\n",
    "                self.biases[j] = np.subtract(self.biases[j], rate * d_biases[j])\n",
    "            if i % 5 == 0:\n",
    "                print(\"loss:\", self.emp_loss(test_labels, test_layers))\n",
    "                print(\"accuracy:\", self.acc(test_labels_number, test_layers))\n",
    "                print(self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61883ae1-0d69-41f5-86c1-5f45d648a5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create net\n",
      "loss: 0.8999932785588928\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for one epoch\n",
      "\n",
      "\n",
      "batch 0\n",
      "loss: 0.9189247613205374\n",
      "accuracy: 0.0970970970970971\n",
      "[array([0.04623288, 0.27341108, 0.65982129, 0.50698741, 0.9616386 ,\n",
      "       0.61455652, 0.79991417, 0.17120959, 0.46731619, 0.32271457]), array([ 0.66615909,  0.0635852 ,  0.22454231,  0.79512373,  0.32667963,\n",
      "        0.11664952,  0.94673637, -0.08296094,  0.17971859,  0.71302279])]\n",
      "\n",
      "\n",
      "batch 1\n",
      "\n",
      "\n",
      "batch 2\n",
      "\n",
      "\n",
      "batch 3\n",
      "\n",
      "\n",
      "batch 4\n",
      "\n",
      "\n",
      "batch 5\n",
      "loss: 0.9202022942315147\n",
      "accuracy: 0.0970970970970971\n",
      "[array([0.04623288, 0.27341108, 0.65982129, 0.50698741, 0.9616386 ,\n",
      "       0.61455652, 0.79991417, 0.17120959, 0.46731619, 0.32271457]), array([ 0.66615909,  0.0635852 ,  0.22454231,  0.79512374,  0.32667963,\n",
      "        0.11664952,  0.94691761, -0.08296094,  0.17971859,  0.71302279])]\n",
      "\n",
      "\n",
      "batch 6\n",
      "\n",
      "\n",
      "batch 7\n",
      "\n",
      "\n",
      "batch 8\n",
      "\n",
      "\n",
      "batch 9\n",
      "\n",
      "\n",
      "batch 10\n",
      "loss: 0.9201431107557198\n",
      "accuracy: 0.0970970970970971\n",
      "[array([0.04623288, 0.27341108, 0.65982129, 0.50698741, 0.9616386 ,\n",
      "       0.61455652, 0.79991417, 0.17120959, 0.46731619, 0.32271457]), array([ 0.6661591 ,  0.06358523,  0.22460195,  0.79539827,  0.32566156,\n",
      "        0.11664959, -1.49230149, -0.08296084,  0.17971883,  0.71416006])]\n",
      "\n",
      "\n",
      "batch 11\n",
      "\n",
      "\n",
      "batch 12\n",
      "\n",
      "\n",
      "batch 13\n",
      "\n",
      "\n",
      "batch 14\n",
      "\n",
      "\n",
      "batch 15\n",
      "loss: 0.9199270368407028\n",
      "accuracy: 0.09309309309309309\n",
      "[array([0.04623288, 0.27341108, 0.65982129, 0.50698741, 0.9616386 ,\n",
      "       0.61455652, 0.79991417, 0.17120959, 0.46731619, 0.32271457]), array([ 0.66622156,  0.06367193, -0.63104136,  0.89518896, -0.21777464,\n",
      "       -0.57203034, -1.49219326, -0.08132399,  0.22983522,  0.63442348])]\n",
      "\n",
      "\n",
      "batch 16\n",
      "\n",
      "\n",
      "batch 17\n",
      "\n",
      "\n",
      "batch 18\n",
      "\n",
      "\n",
      "batch 19\n",
      "\n",
      "\n",
      "batch 20\n",
      "loss: 0.9216337986095692\n",
      "accuracy: 0.0970970970970971\n",
      "[array([0.04622347, 0.27257597, 0.6598213 , 0.50698734, 0.96164012,\n",
      "       0.61450562, 0.79991417, 0.17311635, 0.46729769, 0.32278283]), array([ 0.20877353, -1.38328994, -1.99955742,  0.89525503, -2.53618716,\n",
      "       -3.42763332, -1.15561   , -2.18653746, -0.52054199,  0.65431997])]\n",
      "\n",
      "\n",
      "batch 21\n",
      "\n",
      "\n",
      "batch 22\n",
      "\n",
      "\n",
      "batch 23\n",
      "\n",
      "\n",
      "batch 24\n",
      "\n",
      "\n",
      "batch 25\n",
      "loss: 0.9167412112955127\n",
      "accuracy: 0.0970970970970971\n",
      "[array([0.04622347, 0.27417691, 0.6598213 , 0.50698734, 0.96164038,\n",
      "       0.61450109, 0.79991417, 0.11670345, 0.46729768, 0.32278306]), array([-2.44600553, -1.49087438, -2.74543807,  0.88488116, -2.53618398,\n",
      "       -3.42757783, -3.75493858, -2.65389119, -2.30263301,  1.09084615])]\n",
      "\n",
      "\n",
      "batch 26\n",
      "\n",
      "\n",
      "batch 27\n",
      "\n",
      "\n",
      "batch 28\n",
      "\n",
      "\n",
      "batch 29\n",
      "\n",
      "\n",
      "batch 30\n",
      "loss: 0.9184494901633389\n",
      "accuracy: 0.0970970970970971\n",
      "[array([0.04622346, 0.27213971, 0.6598213 , 0.50698734, 0.96164576,\n",
      "       0.61449683, 0.79991417, 1.30357894, 0.46729766, 0.3227824 ]), array([-2.4460017 , -3.20905248, -4.19984083, -1.03377098, -2.53602942,\n",
      "       -3.39902361, -4.81263645, -2.82792265, -3.61277214, -1.19877551])]\n",
      "\n",
      "\n",
      "batch 31\n",
      "\n",
      "\n",
      "batch 32\n",
      "\n",
      "\n",
      "batch 33\n",
      "\n",
      "\n",
      "batch 34\n",
      "\n",
      "\n",
      "batch 35\n",
      "loss: 0.9138383513697945\n",
      "accuracy: 0.12812812812812813\n",
      "[array([0.04622346, 4.41137428, 0.6598213 , 0.50698734, 0.96163669,\n",
      "       0.61140846, 0.79991417, 1.24023045, 0.46729766, 0.30649166]), array([-2.44571809, -5.85479618, -4.18301984, -2.94628269, -2.53436225,\n",
      "       -3.52180689, -5.45941165, -4.29151267, -3.90940277, -3.03313387])]\n",
      "\n",
      "\n",
      "batch 36\n",
      "\n",
      "\n",
      "batch 37\n",
      "\n",
      "\n",
      "batch 38\n",
      "\n",
      "\n",
      "batch 39\n",
      "\n",
      "\n",
      "batch 40\n",
      "loss: 0.9077563455157602\n",
      "accuracy: 0.13013013013013014\n",
      "[array([ 0.04622346,  0.69328949,  0.6598213 ,  0.50698734,  0.96213266,\n",
      "        0.6128397 ,  0.79991417, -2.11318389,  0.46729766,  0.38939601]), array([-2.71769802, -5.85477892, -3.72685488, -2.94619104, -2.53695528,\n",
      "       -4.35956687, -7.23304094, -4.30070284, -5.27596835, -3.54528099])]\n",
      "\n",
      "\n",
      "batch 41\n",
      "\n",
      "\n",
      "batch 42\n",
      "\n",
      "\n",
      "batch 43\n",
      "\n",
      "\n",
      "batch 44\n",
      "\n",
      "\n",
      "batch 45\n",
      "loss: 0.8964728621446526\n",
      "accuracy: 0.15715715715715717\n",
      "[array([ 0.04622346, -2.17426899,  0.6598213 ,  0.50698734,  0.96434697,\n",
      "        0.61894628,  0.79991417, -2.8865514 ,  0.46729766,  2.35590495]), array([-3.18919269, -5.85223287, -3.89910535, -3.1351558 , -2.75110148,\n",
      "       -4.84406174, -7.09403209, -4.30268954, -5.26149955, -3.77158122])]\n",
      "\n",
      "\n",
      "batch 46\n",
      "\n",
      "\n",
      "batch 47\n",
      "\n",
      "\n",
      "batch 48\n",
      "\n",
      "\n",
      "batch 49\n",
      "\n",
      "\n",
      "batch 50\n",
      "loss: 0.8927525684696714\n",
      "accuracy: 0.2122122122122122\n",
      "[array([ 0.04622346,  0.19901426,  0.6598213 ,  0.50698734,  0.96585771,\n",
      "        0.61712875,  0.79991417, -5.45838089,  0.46729435,  3.63707707]), array([-4.18010322, -6.12770524, -4.29503396, -3.21577468, -3.13612903,\n",
      "       -5.56849461, -6.43965173, -4.955296  , -6.24909367, -4.40835352])]\n",
      "\n",
      "\n",
      "batch 51\n",
      "\n",
      "\n",
      "batch 52\n",
      "\n",
      "\n",
      "batch 53\n",
      "\n",
      "\n",
      "batch 54\n",
      "\n",
      "\n",
      "batch 55\n",
      "loss: 0.9018386533286674\n",
      "accuracy: 0.15115115115115116\n",
      "[array([  0.04622346,   4.17551371,   0.6598213 ,   0.50698734,\n",
      "         0.96621186,   0.53141353,   0.79991417, -11.50800988,\n",
      "         0.46565387,   2.56659046]), array([-5.25504414, -6.8715449 , -4.65432277, -3.31306136, -4.08962588,\n",
      "       -6.55867036, -6.582758  , -5.2953636 , -6.10195536, -5.19483085])]\n",
      "\n",
      "\n",
      "batch 56\n",
      "\n",
      "\n",
      "batch 57\n",
      "\n",
      "\n",
      "batch 58\n",
      "\n",
      "\n",
      "batch 59\n",
      "\n",
      "\n",
      "batch 60\n",
      "loss: 0.8959001723265699\n",
      "accuracy: 0.16616616616616617\n",
      "[array([ 0.04622346,  7.38147625,  0.6598213 ,  0.50698734,  0.96623897,\n",
      "        0.92071722,  0.79991417, -9.01165347,  0.46545433, -0.95130802]), array([-7.11876421, -7.70426711, -5.37306514, -4.75976049, -4.20237007,\n",
      "       -6.26984696, -7.20350352, -5.20616751, -7.05516021, -6.9340236 ])]\n",
      "\n",
      "\n",
      "batch 61\n",
      "\n",
      "\n",
      "batch 62\n",
      "\n",
      "\n",
      "batch 63\n",
      "\n",
      "\n",
      "batch 64\n",
      "\n",
      "\n",
      "batch 65\n",
      "loss: 0.9022514830373546\n",
      "accuracy: 0.12212212212212212\n",
      "[array([  0.04622346,   7.63883934,   0.6598213 ,   0.50698734,\n",
      "         0.96652987,   3.61787286,   0.79991417, -13.45904492,\n",
      "         0.98798931,  -3.22523913]), array([-6.87835716, -8.40747582, -7.23857708, -4.76611403, -5.35139762,\n",
      "       -8.12565027, -7.94355905, -5.7359106 , -7.07609989, -8.20379255])]\n",
      "\n",
      "\n",
      "batch 66\n",
      "\n",
      "\n",
      "batch 67\n",
      "\n",
      "\n",
      "batch 68\n",
      "\n",
      "\n",
      "batch 69\n",
      "\n",
      "\n",
      "batch 70\n",
      "loss: 0.8945433545663632\n",
      "accuracy: 0.14214214214214213\n",
      "[array([  0.04622346,   5.97654575,   0.6598213 ,   0.50698734,\n",
      "         0.9665299 ,   3.16964473,   0.79991417, -14.74528468,\n",
      "         0.90123658,   0.2223191 ]), array([-7.5024432 , -8.92618891, -6.87663785, -5.26730162, -5.48119956,\n",
      "       -7.81831189, -8.33615823, -5.83767403, -7.32446829, -8.12087293])]\n",
      "\n",
      "\n",
      "batch 71\n",
      "\n",
      "\n",
      "batch 72\n",
      "\n",
      "\n",
      "batch 73\n",
      "\n",
      "\n",
      "batch 74\n",
      "\n",
      "\n",
      "batch 75\n",
      "loss: 0.8902262958291577\n",
      "accuracy: 0.19119119119119118\n",
      "[array([  0.04622346,   6.77093684,   0.65982129,   0.50698734,\n",
      "         0.9654005 ,   2.89310985,   0.79991417, -13.73624024,\n",
      "         3.20027248,  -1.21603446]), array([-7.83726674, -9.17893376, -8.0566958 , -6.72894789, -5.67064858,\n",
      "       -8.08605972, -8.95988828, -6.54775465, -7.94631422, -8.16613863])]\n",
      "\n",
      "\n",
      "batch 76\n",
      "\n",
      "\n",
      "batch 77\n",
      "\n",
      "\n",
      "batch 78\n",
      "\n",
      "\n",
      "batch 79\n",
      "\n",
      "\n",
      "batch 80\n",
      "loss: 0.8899962298598745\n",
      "accuracy: 0.16816816816816818\n",
      "[array([  0.04622346,  10.9821357 ,   0.65982129,   0.50698734,\n",
      "         0.9377375 ,   3.62953395,   0.79991417, -13.4865964 ,\n",
      "         3.71095375,   2.12942296]), array([-8.01116229, -9.31909651, -8.2838642 , -7.40086338, -5.42942664,\n",
      "       -9.58344074, -8.73004055, -7.33765979, -7.89037551, -8.72787753])]\n",
      "\n",
      "\n",
      "batch 81\n",
      "\n",
      "\n",
      "batch 82\n",
      "\n",
      "\n",
      "batch 83\n",
      "\n",
      "\n",
      "batch 84\n",
      "\n",
      "\n",
      "batch 85\n",
      "loss: 0.8911810241309117\n",
      "accuracy: 0.15515515515515516\n",
      "[array([  0.04622346,  10.02727893,   0.65982129,   0.50698734,\n",
      "        -0.15462545,   3.51702048,   0.79991417, -13.5819708 ,\n",
      "         3.96797771,  -3.75274462]), array([ -8.35245167,  -9.52372904,  -9.31214092,  -7.91348171,\n",
      "        -5.87115669, -10.20810757,  -9.20902178,  -9.01232002,\n",
      "        -9.03773736,  -9.16132605])]\n",
      "\n",
      "\n",
      "batch 86\n",
      "\n",
      "\n",
      "batch 87\n",
      "\n",
      "\n",
      "batch 88\n",
      "\n",
      "\n",
      "batch 89\n",
      "\n",
      "\n",
      "batch 90\n",
      "loss: 0.8718357920299019\n",
      "accuracy: 0.25225225225225223\n",
      "[array([ 0.04622346,  9.37335625,  0.65982129,  0.50698734,  5.75129628,\n",
      "       -1.62911018,  0.79991417, -8.31872078,  5.4305505 , -3.2102565 ]), array([ -9.19853111,  -9.49501762,  -9.83215623,  -8.00391404,\n",
      "        -6.17739901, -10.34747257,  -9.4336491 ,  -9.18618198,\n",
      "        -8.99456534,  -9.15367242])]\n",
      "\n",
      "\n",
      "batch 91\n",
      "\n",
      "\n",
      "batch 92\n",
      "\n",
      "\n",
      "batch 93\n",
      "\n",
      "\n",
      "batch 94\n",
      "\n",
      "\n",
      "batch 95\n",
      "loss: 0.8697938870779236\n",
      "accuracy: 0.2502502502502503\n",
      "[array([ 0.04622346, 11.15435116,  0.65982129,  0.50698734,  5.93775547,\n",
      "       -0.45419501,  0.79991417, -7.65064275,  5.44332927, -4.49511536]), array([ -9.09818662,  -9.46565134, -11.06596682,  -7.7360786 ,\n",
      "        -6.49198629, -10.77456372, -10.12814825,  -9.97884621,\n",
      "        -8.86937299,  -9.49996081])]\n",
      "\n",
      "\n",
      "batch 96\n",
      "\n",
      "\n",
      "batch 97\n",
      "\n",
      "\n",
      "batch 98\n",
      "\n",
      "\n",
      "batch 99\n",
      "\n",
      "\n",
      "batch 100\n",
      "loss: 0.8665638705560242\n",
      "accuracy: 0.26226226226226224\n",
      "[array([  0.04622346,  10.89138073,   0.65982129,   0.50698734,\n",
      "         7.20695672,   1.45948453,   0.79991417,  -9.88224286,\n",
      "         5.58403556, -12.35951941]), array([ -9.28778181,  -9.70120657, -10.98452936,  -8.05329933,\n",
      "        -6.77582072, -11.36852158, -11.08868589, -10.92427355,\n",
      "        -9.11335901,  -9.80948186])]\n",
      "\n",
      "\n",
      "batch 101\n",
      "\n",
      "\n",
      "batch 102\n",
      "\n",
      "\n",
      "batch 103\n",
      "\n",
      "\n",
      "batch 104\n",
      "\n",
      "\n",
      "batch 105\n",
      "loss: 0.8651783238002272\n",
      "accuracy: 0.27927927927927926\n",
      "[array([  0.04622346,  10.7287701 ,   0.65982129,   0.50698734,\n",
      "         7.49547833,   2.82424149,   0.79991417, -10.12804565,\n",
      "         7.43706367, -12.35913718]), array([ -9.07666485,  -9.5406584 , -10.81330149,  -8.18816168,\n",
      "        -7.42642229, -11.75064769, -11.01598548, -11.11291585,\n",
      "        -9.04367076, -10.16966143])]\n",
      "\n",
      "\n",
      "batch 106\n",
      "\n",
      "\n",
      "batch 107\n",
      "\n",
      "\n",
      "batch 108\n",
      "\n",
      "\n",
      "batch 109\n",
      "\n",
      "\n",
      "batch 110\n",
      "loss: 0.8580222583975333\n",
      "accuracy: 0.28928928928928926\n",
      "[array([  0.04622346,  11.63058793,   0.65982129,   0.50698734,\n",
      "         6.66481242,   1.93115901,   0.79991417,  -8.40397613,\n",
      "         6.76518638, -12.36052798]), array([ -9.76625304,  -9.14878374, -10.80852607,  -9.19416829,\n",
      "        -7.70812818, -12.53414856, -10.93914652, -12.18048654,\n",
      "        -8.39451277, -10.96501801])]\n",
      "\n",
      "\n",
      "batch 111\n",
      "\n",
      "\n",
      "batch 112\n",
      "\n",
      "\n",
      "batch 113\n",
      "\n",
      "\n",
      "batch 114\n",
      "\n",
      "\n",
      "batch 115\n",
      "loss: 0.8628286569331186\n",
      "accuracy: 0.23723723723723725\n",
      "[array([  0.04622346,  11.08358854,   0.65982129,   0.50698734,\n",
      "         7.83504758,   0.57020726,   0.79991417,  -5.93523396,\n",
      "         6.51861391, -12.35360993]), array([ -9.73915606,  -9.06954507, -11.0896869 ,  -9.53771803,\n",
      "        -8.5103696 , -12.66013569, -11.16253962, -12.3030894 ,\n",
      "        -8.02036023, -11.05908837])]\n",
      "\n",
      "\n",
      "batch 116\n",
      "\n",
      "\n",
      "batch 117\n",
      "\n",
      "\n",
      "batch 118\n",
      "\n",
      "\n",
      "batch 119\n",
      "\n",
      "\n",
      "batch 120\n",
      "loss: 0.8776198889018638\n",
      "accuracy: 0.23123123123123124\n",
      "[array([  0.04622346,   9.48229232,   0.65982129,   0.50698734,\n",
      "         7.17758378,  -1.27193996,   0.79991417,  -6.69221061,\n",
      "         6.01470794, -12.35316273]), array([-10.04168709,  -8.58106838, -11.09417995,  -9.54004862,\n",
      "        -8.36620655, -12.96373477, -10.62150936, -12.6589958 ,\n",
      "        -7.98447221, -11.52474862])]\n",
      "\n",
      "\n",
      "batch 121\n",
      "\n",
      "\n",
      "batch 122\n",
      "\n",
      "\n",
      "batch 123\n",
      "\n",
      "\n",
      "batch 124\n",
      "\n",
      "\n",
      "batch 125\n",
      "loss: 0.8622513275582276\n",
      "accuracy: 0.28928928928928926\n",
      "[array([  0.04622346,  10.1211436 ,   0.65982129,   0.50698734,\n",
      "         7.72315323,   1.9733008 ,   0.79991417,  -6.89136951,\n",
      "         4.94643012, -15.27216294]), array([ -9.53775668,  -7.32353133, -10.8572013 ,  -9.5286227 ,\n",
      "        -8.44510556, -13.26038432, -11.36003821, -13.14788994,\n",
      "        -7.80278886, -11.7240779 ])]\n",
      "\n",
      "\n",
      "batch 126\n",
      "\n",
      "\n",
      "batch 127\n",
      "\n",
      "\n",
      "batch 128\n",
      "\n",
      "\n",
      "batch 129\n",
      "\n",
      "\n",
      "batch 130\n",
      "loss: 0.8655166899884827\n",
      "accuracy: 0.2802802802802803\n",
      "[array([  0.04622346,   8.66791135,   0.65982129,   0.50698734,\n",
      "         7.17916446,   0.29547496,   0.79991417,  -2.8051653 ,\n",
      "         5.48683868, -15.27073808]), array([-10.56463468,  -7.74026664, -11.27965323,  -8.91368024,\n",
      "        -9.79675573, -14.00811723, -11.39215763, -13.44535513,\n",
      "        -8.38791788, -12.32727607])]\n",
      "\n",
      "\n",
      "batch 131\n",
      "\n",
      "\n",
      "batch 132\n",
      "\n",
      "\n",
      "batch 133\n",
      "\n",
      "\n",
      "batch 134\n",
      "\n",
      "\n",
      "batch 135\n",
      "loss: 0.8554301455597743\n",
      "accuracy: 0.27627627627627627\n",
      "[array([  0.04622346,   9.54648098,   0.65982129,   0.50698734,\n",
      "         8.53485537,   3.5463045 ,   0.79991417,  -1.42311753,\n",
      "         4.45671282, -15.27003384]), array([-10.48035959,  -7.47045979, -10.93571533,  -9.12905631,\n",
      "       -10.34419477, -14.28802193, -12.05462508, -14.03579679,\n",
      "        -8.17530366, -12.47590009])]\n",
      "\n",
      "\n",
      "batch 136\n",
      "\n",
      "\n",
      "batch 137\n",
      "\n",
      "\n",
      "batch 138\n",
      "\n",
      "\n",
      "batch 139\n",
      "\n",
      "\n",
      "batch 140\n",
      "loss: 0.8538635109613725\n",
      "accuracy: 0.3113113113113113\n",
      "[array([  0.04622346,  11.51992163,   0.65982129,   0.50698734,\n",
      "        10.35947187,   1.15189555,   0.79991417,  -6.23437366,\n",
      "         1.46580851, -15.27186361]), array([ -9.46637199,  -7.82311453, -11.105583  ,  -9.43622259,\n",
      "       -11.00708959, -14.74407558, -11.96625351, -14.19009996,\n",
      "        -8.70724701, -12.59244031])]\n",
      "\n",
      "\n",
      "batch 141\n",
      "\n",
      "\n",
      "batch 142\n",
      "\n",
      "\n",
      "batch 143\n",
      "\n",
      "\n",
      "batch 144\n",
      "\n",
      "\n",
      "batch 145\n",
      "loss: 0.8617430748436561\n",
      "accuracy: 0.25425425425425424\n",
      "[array([  0.04622346,   9.1083188 ,   0.65982129,   0.50698734,\n",
      "        10.37965057,  -0.58760383,   0.79991417,  -0.83801009,\n",
      "         1.83237336, -15.27456969]), array([ -9.01147009,  -8.70814763, -11.42753728,  -9.23745774,\n",
      "       -11.76225352, -15.4011633 , -12.17139977, -13.9444047 ,\n",
      "        -8.91078826, -13.13060442])]\n",
      "\n",
      "\n",
      "batch 146\n",
      "\n",
      "\n",
      "batch 147\n",
      "\n",
      "\n",
      "batch 148\n",
      "\n",
      "\n",
      "batch 149\n",
      "\n",
      "\n",
      "batch 150\n",
      "loss: 0.852700826319186\n",
      "accuracy: 0.3153153153153153\n",
      "[array([  0.04622266,   9.92194679,   0.65982129,   0.50698734,\n",
      "        10.32340275,   1.4668451 ,   0.79991417,  -1.62051318,\n",
      "         2.77250314, -15.27456318]), array([ -9.28117533,  -8.69754604, -11.92683863,  -9.33464272,\n",
      "       -11.92830793, -15.7218219 , -12.29859696, -14.82808809,\n",
      "        -8.97757504, -12.86900172])]\n",
      "\n",
      "\n",
      "batch 151\n",
      "\n",
      "\n",
      "batch 152\n",
      "\n",
      "\n",
      "batch 153\n",
      "\n",
      "\n",
      "batch 154\n",
      "\n",
      "\n",
      "batch 155\n",
      "loss: 0.8372655615549407\n",
      "accuracy: 0.3783783783783784\n",
      "[array([  0.04622297,  11.89021464,   0.65982129,   0.50698734,\n",
      "        10.3786132 ,  -0.8875866 ,   0.79991417,   3.19761301,\n",
      "         3.0219306 , -15.27450083]), array([ -9.85488454,  -9.36468971, -12.34870547, -10.80552537,\n",
      "       -12.80411797, -16.48537856, -12.8349076 , -15.48683434,\n",
      "        -9.07685739, -13.19166775])]\n",
      "\n",
      "\n",
      "batch 156\n",
      "\n",
      "\n",
      "batch 157\n",
      "\n",
      "\n",
      "batch 158\n",
      "\n",
      "\n",
      "batch 159\n",
      "\n",
      "\n",
      "batch 160\n",
      "loss: 0.8471031826674188\n",
      "accuracy: 0.34234234234234234\n",
      "[array([  0.04619367,  12.5027441 ,   0.65982129,   0.50698734,\n",
      "        10.50312473,  -2.08918485,   0.79991417,   5.94779996,\n",
      "         1.66366616, -15.2751526 ]), array([-10.06948068,  -8.65259697, -12.61960656, -10.27607378,\n",
      "       -13.16697488, -16.76532537, -12.62581049, -15.39349479,\n",
      "        -9.07372888, -13.72302314])]\n",
      "\n",
      "\n",
      "batch 161\n",
      "\n",
      "\n",
      "batch 162\n",
      "\n",
      "\n",
      "batch 163\n",
      "\n",
      "\n",
      "batch 164\n",
      "\n",
      "\n",
      "batch 165\n",
      "loss: 0.8550278718241876\n",
      "accuracy: 0.3023023023023023\n",
      "[array([  0.04613236,  12.6076913 ,   0.65982129,   0.50698734,\n",
      "        11.13344123,   5.04914398,   0.79991417,   5.3649494 ,\n",
      "         1.07400663, -15.27515832]), array([ -9.4805198 ,  -9.05311446, -13.03340833, -10.18610352,\n",
      "       -13.57969615, -16.83212244, -13.42261089, -15.58034087,\n",
      "        -9.0890227 , -13.35643698])]\n",
      "\n",
      "\n",
      "batch 166\n",
      "\n",
      "\n",
      "batch 167\n",
      "\n",
      "\n",
      "batch 168\n",
      "\n",
      "\n",
      "batch 169\n",
      "\n",
      "\n",
      "batch 170\n",
      "loss: 0.8459853640594774\n",
      "accuracy: 0.3303303303303303\n",
      "[array([  0.04619096,  12.63739617,   0.65982129,   0.50698734,\n",
      "        11.09007385,   2.16698607,   0.79991417,   7.69062701,\n",
      "         3.12980889, -15.27523824]), array([ -9.50442349,  -8.59853049, -13.38796232, -11.41565385,\n",
      "       -13.51177145, -16.40342084, -13.58727071, -15.44490685,\n",
      "        -9.17967244, -13.55650378])]\n",
      "\n",
      "\n",
      "batch 171\n",
      "\n",
      "\n",
      "batch 172\n",
      "\n",
      "\n",
      "batch 173\n",
      "\n",
      "\n",
      "batch 174\n",
      "\n",
      "\n",
      "batch 175\n",
      "loss: 0.8582497492831562\n",
      "accuracy: 0.3013013013013013\n",
      "[array([  0.66735016,  13.97726477,   0.65982129,   0.50698734,\n",
      "        10.48045377,  -0.36457908,   0.79991417,   7.41160825,\n",
      "         3.48589592, -15.27539807]), array([ -9.5307084 ,  -7.94071669, -14.73794703, -11.40941821,\n",
      "       -14.57672146, -16.5336849 , -13.1577317 , -15.64019199,\n",
      "        -8.97101859, -14.03331495])]\n",
      "\n",
      "\n",
      "batch 176\n",
      "\n",
      "\n",
      "batch 177\n",
      "\n",
      "\n",
      "batch 178\n",
      "\n",
      "\n",
      "batch 179\n",
      "\n",
      "\n",
      "batch 180\n",
      "loss: 0.8464455705128938\n",
      "accuracy: 0.3433433433433433\n",
      "[array([  1.53363802,  15.62840442,   0.65982129,   0.50698734,\n",
      "        10.44062425,   0.54846125,   0.79991417,   7.41200251,\n",
      "         3.31852343, -15.27422415]), array([-10.11538538,  -8.78451275, -14.8101915 , -11.79802798,\n",
      "       -14.74183733, -16.89612262, -13.00197699, -16.24946814,\n",
      "        -8.93172894, -14.14822095])]\n",
      "\n",
      "\n",
      "batch 181\n",
      "\n",
      "\n",
      "batch 182\n",
      "\n",
      "\n",
      "batch 183\n",
      "\n",
      "\n",
      "batch 184\n",
      "\n",
      "\n",
      "batch 185\n",
      "loss: 0.8547161701975304\n",
      "accuracy: 0.3153153153153153\n",
      "[array([  2.81916839,  14.92073836,   0.65982129,   0.50698734,\n",
      "        10.0952097 ,   0.05597122,   0.79991417,   9.08651202,\n",
      "         2.900754  , -15.27422916]), array([ -9.24372467,  -8.78031134, -14.93944258, -11.73087186,\n",
      "       -15.12886375, -17.50456409, -13.75527697, -16.02284752,\n",
      "        -9.19423204, -13.75948453])]\n",
      "\n",
      "\n",
      "batch 186\n",
      "\n",
      "\n",
      "batch 187\n",
      "\n",
      "\n",
      "batch 188\n",
      "\n",
      "\n",
      "batch 189\n",
      "\n",
      "\n",
      "batch 190\n",
      "loss: 0.8610096080663006\n",
      "accuracy: 0.28928928928928926\n",
      "[array([  4.77692158,  14.93613888,   0.65982129,   0.50698734,\n",
      "        12.13801749,   1.30894128,   0.79991417,  11.15324849,\n",
      "         2.6088316 , -15.25616203]), array([ -9.55108035,  -8.6908586 , -15.20395925, -12.16750782,\n",
      "       -15.66399395, -17.87560285, -14.23964821, -16.25966835,\n",
      "        -9.21138893, -14.27043938])]\n",
      "\n",
      "\n",
      "batch 191\n",
      "\n",
      "\n",
      "batch 192\n",
      "\n",
      "\n",
      "batch 193\n",
      "\n",
      "\n",
      "batch 194\n",
      "\n",
      "\n",
      "batch 195\n",
      "loss: 0.8586693422279187\n",
      "accuracy: 0.2772772772772773\n",
      "[array([  4.77711114,  14.78768043,   0.65982129,   0.50698734,\n",
      "        12.13761582,   3.34132212,   0.79991417,  10.17281248,\n",
      "         1.93079009, -15.25632257]), array([ -9.57272884,  -9.87987266, -15.55628678, -12.13033878,\n",
      "       -15.789404  , -17.77648385, -14.03620452, -17.31762033,\n",
      "        -9.23974295, -14.03059613])]\n",
      "\n",
      "\n",
      "batch 196\n",
      "\n",
      "\n",
      "batch 197\n",
      "\n",
      "\n",
      "batch 198\n",
      "\n",
      "\n",
      "batch 199\n",
      "\n",
      "\n",
      "batch 200\n",
      "loss: 0.8609676779266899\n",
      "accuracy: 0.28128128128128127\n",
      "[array([  5.20822382,  14.42345095,   0.65982129,   0.50698732,\n",
      "        12.13861441,   3.51529467,   0.79991417,   6.42465958,\n",
      "         2.28275677, -14.97479813]), array([-10.21268551, -10.12430724, -15.22072719, -12.3507557 ,\n",
      "       -15.91099219, -17.79730832, -14.01524803, -17.35122041,\n",
      "        -9.24134768, -14.03158579])]\n",
      "\n",
      "\n",
      "batch 201\n",
      "\n",
      "\n",
      "batch 202\n",
      "\n",
      "\n",
      "batch 203\n",
      "\n",
      "\n",
      "batch 204\n",
      "\n",
      "\n",
      "batch 205\n",
      "loss: 0.874265380327918\n",
      "accuracy: 0.23923923923923923\n",
      "[array([  5.20438083,  14.50875419,   0.65982129,   0.50698732,\n",
      "        12.1392237 ,  -0.87716562,   0.79991417,   3.15134829,\n",
      "        -0.25610485, -14.97478279]), array([ -9.44882613, -10.53894863, -14.73265225, -11.68637048,\n",
      "       -15.63856426, -17.938716  , -14.15940311, -17.05761673,\n",
      "        -9.20129245, -14.50913942])]\n",
      "\n",
      "\n",
      "batch 206\n",
      "\n",
      "\n",
      "batch 207\n",
      "\n",
      "\n",
      "batch 208\n",
      "\n",
      "\n",
      "batch 209\n",
      "\n",
      "\n",
      "batch 210\n",
      "loss: 0.8464988863392486\n",
      "accuracy: 0.34134134134134136\n",
      "[array([  5.204865  ,  14.16835977,   0.65982129,   0.50698732,\n",
      "        12.13905789,  -3.86995589,   0.79991417,   4.2840467 ,\n",
      "        -0.46985547, -14.97480708]), array([ -9.22186214, -10.63769745, -15.63810922, -12.61784395,\n",
      "       -15.91036386, -17.70376301, -13.8095779 , -17.38383301,\n",
      "        -9.42313555, -14.80357544])]\n",
      "\n",
      "\n",
      "batch 211\n",
      "\n",
      "\n",
      "batch 212\n",
      "\n",
      "\n",
      "batch 213\n",
      "\n",
      "\n",
      "batch 214\n",
      "\n",
      "\n",
      "batch 215\n",
      "loss: 0.8500652596415589\n",
      "accuracy: 0.31931931931931934\n",
      "[array([  4.7195369 ,  14.12030718,   0.65982129,   0.50698731,\n",
      "        12.17705311,  -4.10226371,   0.79991417,  -0.35854446,\n",
      "        -0.27217699, -14.97480049]), array([ -9.53039768, -10.68070297, -13.75271582, -11.81566207,\n",
      "       -16.04573785, -17.70376329, -13.97555986, -17.22589081,\n",
      "        -9.42319011, -14.80357557])]\n",
      "\n",
      "\n",
      "batch 216\n",
      "\n",
      "\n",
      "batch 217\n",
      "\n",
      "\n",
      "batch 218\n",
      "\n",
      "\n",
      "batch 219\n",
      "\n",
      "\n",
      "batch 220\n",
      "loss: 0.8475954475620032\n",
      "accuracy: 0.34134134134134136\n",
      "[array([  4.6190894 ,  14.52602233,   0.65982129,   0.50698731,\n",
      "        12.17980348,  -3.85254697,   0.79991417,  -1.41706525,\n",
      "         0.6235202 , -14.86202983]), array([ -8.97847386, -10.74174221, -14.00322569, -12.39313774,\n",
      "       -16.65077321, -17.73763101, -13.91412416, -17.51413136,\n",
      "        -9.4272326 , -14.80408323])]\n",
      "\n",
      "\n",
      "batch 221\n",
      "\n",
      "\n",
      "batch 222\n",
      "\n",
      "\n",
      "batch 223\n",
      "\n",
      "\n",
      "batch 224\n",
      "\n",
      "\n",
      "batch 225\n",
      "loss: 0.84928713447391\n",
      "accuracy: 0.33133133133133136\n",
      "[array([  4.5778608 ,  14.52207226,   0.65982129,   0.50698731,\n",
      "        12.17920846,  -4.25571523,   0.79991417,  -0.79627002,\n",
      "         0.44353607, -14.93208981]), array([ -8.79680768, -10.77566072, -14.75984574, -12.2430693 ,\n",
      "       -16.83669107, -17.73870221, -13.92857741, -17.37970834,\n",
      "        -9.42781822, -14.80410854])]\n",
      "\n",
      "\n",
      "batch 226\n",
      "\n",
      "\n",
      "batch 227\n",
      "\n",
      "\n",
      "batch 228\n",
      "\n",
      "\n",
      "batch 229\n",
      "\n",
      "\n",
      "batch 230\n",
      "loss: 0.8534468420439931\n",
      "accuracy: 0.3183183183183183\n",
      "[array([  4.57292813,  14.47868163,   0.65982129,   0.50698727,\n",
      "        12.1791775 ,  -6.16185544,   0.79991417,  -2.81014617,\n",
      "         0.43551382, -14.93212154]), array([ -9.82522342, -11.12047266, -14.45872949, -12.58994465,\n",
      "       -16.86469808, -17.73841545, -13.70974372, -18.03498722,\n",
      "        -9.42783649, -14.80410852])]\n",
      "\n",
      "\n",
      "batch 231\n",
      "\n",
      "\n",
      "batch 232\n",
      "\n",
      "\n",
      "batch 233\n",
      "\n",
      "\n",
      "batch 234\n",
      "\n",
      "\n",
      "batch 235\n",
      "loss: 0.8607586568890866\n",
      "accuracy: 0.28928928928928926\n",
      "[array([  4.38641301,  14.79729331,   0.65982129,   0.50698727,\n",
      "        12.02173682,  -6.38906538,   0.79991417,  -1.25439569,\n",
      "         0.45087239, -14.93209143]), array([ -9.95588709, -10.98610987, -14.11202658, -11.53507337,\n",
      "       -17.04887609, -17.73841612, -13.83127064, -18.22818518,\n",
      "        -9.42970717, -14.80414811])]\n",
      "\n",
      "\n",
      "batch 236\n",
      "\n",
      "\n",
      "batch 237\n",
      "\n",
      "\n",
      "batch 238\n",
      "\n",
      "\n",
      "batch 239\n",
      "\n",
      "\n",
      "batch 240\n",
      "loss: 0.8447533652315675\n",
      "accuracy: 0.3383383383383383\n",
      "[array([  4.33132059,  14.73009818,   0.65982129,   0.50698726,\n",
      "        12.01494134,  -7.83176902,   0.79991417,   1.0133976 ,\n",
      "         0.45586112, -14.9321244 ]), array([ -9.39637032, -11.48110135, -14.39561648, -11.9391269 ,\n",
      "       -17.18902958, -17.73841619, -13.76634206, -18.22752475,\n",
      "        -9.42973222, -14.80414814])]\n",
      "\n",
      "\n",
      "batch 241\n",
      "\n",
      "\n",
      "batch 242\n",
      "\n",
      "\n",
      "batch 243\n",
      "\n",
      "\n",
      "batch 244\n",
      "\n",
      "\n",
      "batch 245\n",
      "loss: 0.8524700904181197\n",
      "accuracy: 0.33733733733733734\n",
      "[array([  3.8225476 ,  15.38225898,   0.65982129,   0.50698722,\n",
      "        12.02582302,  -8.25941406,   0.79991417,   1.16482691,\n",
      "        -1.41437256, -14.97202851]), array([ -9.41741538, -11.32541869, -14.03094081, -12.24878943,\n",
      "       -17.39467793, -17.88994163, -13.99214542, -18.32005875,\n",
      "        -9.47329711, -14.80752338])]\n",
      "\n",
      "\n",
      "batch 246\n",
      "\n",
      "\n",
      "batch 247\n",
      "\n",
      "\n",
      "batch 248\n",
      "\n",
      "\n",
      "batch 249\n",
      "\n",
      "\n",
      "batch 250\n",
      "loss: 0.8547876205875883\n",
      "accuracy: 0.3213213213213213\n",
      "[array([  3.4817578 ,  15.34789192,   0.65982129,   0.5069872 ,\n",
      "        12.0319842 ,  -7.35518619,   0.79991417,   1.96351769,\n",
      "        -0.99132813, -14.97242648]), array([-10.61247681, -11.64375405, -14.14591977, -12.32810773,\n",
      "       -17.3943775 , -17.88994162, -12.85480735, -18.74657699,\n",
      "        -9.47328719, -14.80752338])]\n",
      "\n",
      "\n",
      "batch 251\n",
      "\n",
      "\n",
      "batch 252\n",
      "\n",
      "\n",
      "batch 253\n",
      "\n",
      "\n",
      "batch 254\n",
      "\n",
      "\n",
      "batch 255\n",
      "loss: 0.8620412859675461\n",
      "accuracy: 0.2882882882882883\n",
      "[array([  3.48177894,  15.34976767,   0.65982129,   0.5069872 ,\n",
      "        12.03296067,  -6.07349334,   0.79991417,  -1.47500041,\n",
      "        -0.99532344, -14.9725234 ]), array([-11.12063438, -11.86397714, -14.16962843, -11.97372351,\n",
      "       -17.64224945, -17.88994168, -13.1040055 , -18.71636888,\n",
      "        -9.46617042, -14.80752333])]\n",
      "\n",
      "\n",
      "batch 256\n",
      "\n",
      "\n",
      "batch 257\n",
      "\n",
      "\n",
      "batch 258\n",
      "\n",
      "\n",
      "batch 259\n",
      "\n",
      "\n",
      "batch 260\n",
      "loss: 0.8632737137952099\n",
      "accuracy: 0.2782782782782783\n",
      "[array([  3.47047   ,  15.34991147,   0.65982129,   0.50698707,\n",
      "        11.92323333,  -5.26051382,   0.79991417,  -1.91464356,\n",
      "        -1.07719633, -14.97251063]), array([-11.09159869, -11.54722167, -14.23267494, -11.78771754,\n",
      "       -17.39061365, -17.8899417 , -13.76659135, -18.69203221,\n",
      "        -9.46620472, -14.80752324])]\n",
      "\n",
      "\n",
      "batch 261\n",
      "\n",
      "\n",
      "batch 262\n",
      "\n",
      "\n",
      "batch 263\n",
      "\n",
      "\n",
      "batch 264\n",
      "\n",
      "\n",
      "batch 265\n",
      "loss: 0.8508955117518702\n",
      "accuracy: 0.32932932932932935\n",
      "[array([  3.1920576 ,  15.33477153,   0.65982129,   0.50724125,\n",
      "        11.92343722,  -5.59043083,   0.79991417,  -0.80134614,\n",
      "         0.69756292, -14.97248061]), array([-10.87644194, -11.44472991, -14.32678256, -12.03076424,\n",
      "       -17.39043615, -17.8899417 , -13.74100814, -18.71406887,\n",
      "        -9.46614977, -14.80752297])]\n",
      "\n",
      "\n",
      "batch 266\n",
      "\n",
      "\n",
      "batch 267\n",
      "\n",
      "\n",
      "batch 268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#plt.imshow(train_imgs[1])\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#plt.show()\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#plt.imshow(train_imgs[2])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(testnet.forward(train_input_layers[1]))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#print(testnet.forward(train_input_layers[2]))\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain for one epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m testnet\u001b[38;5;241m.\u001b[39mtrain(train_layers, train_labels, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[40], line 146\u001b[0m, in \u001b[0;36mNet.train\u001b[1;34m(self, data, labels, batch_size, rate, batches)\u001b[0m\n\u001b[0;32m    144\u001b[0m     d_biases\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])))\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_batched[i])):\n\u001b[1;32m--> 146\u001b[0m     this_d_weights, this_d_biases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackprop(labels_batched[i][j], data_batched[i][j])\n\u001b[0;32m    147\u001b[0m     d_weights_list\u001b[38;5;241m.\u001b[39mappend(this_d_weights)\n\u001b[0;32m    148\u001b[0m     d_biases_list\u001b[38;5;241m.\u001b[39mappend(this_d_biases)\n",
      "Cell \u001b[1;32mIn[40], line 113\u001b[0m, in \u001b[0;36mNet.backprop\u001b[1;34m(self, label, example)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet[i])):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;66;03m#calculates z for the whole layer (layer i)\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m         z_layer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i][k], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[i][k]\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;66;03m#calculates z for this specific node (layer i, index j)\u001b[39;00m\n\u001b[0;32m    115\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i][k][j] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet[i][j] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[i][k]\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"create net\")\n",
    "testnet = Net((784, 10, 10))\n",
    "print(\"loss:\", testnet.emp_loss(test_labels, test_layers))\n",
    "#print(\"net created, calculating initial loss\")\n",
    "#print(testnet.loss(test_layers, test_labels))\n",
    "#testnet.dump()\n",
    "\n",
    "img0 = np.array(data[0][1:785])\n",
    "plt.imshow(np.reshape(img0, (28,28)))\n",
    "plt.show()\n",
    "#plt.imshow(train_imgs[1])\n",
    "#plt.show()\n",
    "#plt.imshow(train_imgs[2])\n",
    "#plt.show()\n",
    "#print(testnet.forward(data[0][1:785]))\n",
    "#print(testnet.forward(train_input_layers[1]))\n",
    "#print(testnet.forward(train_input_layers[2]))\n",
    "\n",
    "print(\"train for one epoch\")\n",
    "testnet.train(train_layers, train_labels, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91531e-58d1-4ef8-8801-f595f8caab78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
